{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Questions\n",
    "\n",
    "\n",
    "## How To Develop a Machine Learning Model From Scratch\n",
    "\n",
    "1. Define adequately our problem (objective, desired outputs‚Ä¶).\n",
    "2. Gather data.\n",
    "3. Choose a measure of success.\n",
    "4. Set an evaluation protocol and the different protocols available.\n",
    "5. Prepare the data (dealing with missing values, with categorial values‚Ä¶).\n",
    "6. Spilit correctly the data.\n",
    "7. Differentiate between over and underfitting, defining what they are and explaining the best ways to avoid them.\n",
    "8. An overview of how a model learns.\n",
    "9. What is regularization and when is appropiate to use it.\n",
    "10. Develop a benchmark model.\n",
    "11. Choose an adequate model and tune it to get the best performance possible.\n",
    "\n",
    "https://towardsdatascience.com/machine-learning-general-process-8f1b510bd8af\n",
    "\n",
    "## What‚Äôs the difference between a generative and discriminative model? Can you give me an example of each?\n",
    "\n",
    "### Generative: model distribution. Discriminative: learn boundary\n",
    "\n",
    "Generative models model the distribution of individual classes. Generative algorithms make some kind of structure assumptions on your model\n",
    "\n",
    "Discriminative models learn the (hard or soft) boundary between classes. SVMs and decision trees are discriminative because they learn explicit boundaries between classes.\n",
    "\n",
    "https://stats.stackexchange.com/questions/12421/generative-vs-discriminative\n",
    "\n",
    "## Difference between linear regression and logistic regression?\n",
    "\n",
    "### Linear: continuous. Logistic: categorical\n",
    "\n",
    "Linear regression is used to predict the continuous dependent variable using a given set of independent variables. Cost function: least squares\n",
    "\n",
    "Logistic Regression is used to predict the categorical dependent variable using a given set of independent variables. Mathematically, a logistic regression model predicts P(Y=1) as a function of X. Can be binary, or multicategorical.\n",
    "\n",
    "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_classification_algorithms_logistic_regression.htm\n",
    "\n",
    "## How does LR learn?\n",
    "\n",
    "### Linear: least square. Logistic: sigmoid\n",
    "\n",
    "Linear: Fitting a line through data, minimizing lost, lost is least square, or sum of squared error\n",
    "\n",
    "Logistic: sigmoid function\n",
    "\n",
    "https://towardsdatascience.com/introduction-to-linear-regression-and-polynomial-regression-f8adc96f31cb\n",
    "\n",
    "https://towardsdatascience.com/introduction-to-logistic-regression-66248243c148\n",
    "\n",
    "## Difference between kNN and k-meansÔºü\n",
    "\n",
    "\n",
    "### kNN: supervised classification and regression. K-means: unsupervised clustering\n",
    "\n",
    "They are completely different methods. The fact that they both have the letter K in their name is a coincidence.\n",
    "\n",
    "KNN represents a supervised classification algorithm that will give new data points accordingly to the k number or the closest data points. In order to determine the classification of a point, KNN combines the classification of the K nearest points. It is supervised because you are trying to classify a point based on the known classification of other points.\n",
    "\n",
    "Pro: KNN have no training period, new data can be added seamlessly, easy to implement. Con: Poor for large dataset or high dimension, need feature scaling, sensitive to noise, missing value and outlier.\n",
    "\n",
    "k-means clustering is an unsupervised clustering algorithm that gathers and groups data into k number of clusters. K-means tries to partition a set of points into K sets (clusters) such that the points in each cluster tend to be near each other. It is unsupervised because the points have no external classification.\n",
    "\n",
    "Both KNN and k-means clustering represent distance-based algorithms that rely on a metric\n",
    "\n",
    "https://pythonprogramminglanguage.com/how-is-the-k-nearest-neighbor-algorithm-different-from-k-means-clustering/\n",
    "https://stats.stackexchange.com/questions/56500/what-are-the-main-differences-between-k-means-and-k-nearest-neighbours\n",
    "http://theprofessionalspoint.blogspot.com/2019/02/advantages-and-disadvantages-of-knn.html\n",
    "\n",
    "## How does KNN and K-means learn?\n",
    "\n",
    "### KNN: Lazy learner, no training. K-means\n",
    "\n",
    "\n",
    "ùëò -NN does not have a loss function that can be minimized during training. In fact, this algorithm is not trained at all. The only \"training\" that happens for ùëò-NN, is memorising the data (creating a local copy), so that during prediction you can do a search and majority vote. Technically, no function is fitted to the data, and so, no optimization is done (it cannot be trained using gradient descent).\n",
    "\n",
    "https://stats.stackexchange.com/questions/420416/does-knn-have-a-loss-function\n",
    "\n",
    "### K-means From Scratch:\n",
    "\n",
    "https://towardsdatascience.com/a-complete-k-mean-clustering-algorithm-from-scratch-in-python-step-by-step-guide-1eb05cdcd461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian modelling\n",
    "\n",
    "### NBC: Eager learner, fast, but assume features are independent\n",
    "\n",
    "***What is Bayes‚Äô Theorem? How is it useful in a machine learning context?*** \n",
    "\n",
    "Bayes' theorem is also known as Bayes' Rule or Bayes' law, which is used to determine the probability of a hypothesis with prior knowledge. It depends on the conditional probability.\n",
    "\n",
    "It provides a way of thinking about the relationship between data and a model. A machine learning algorithm or model is a specific way of thinking about the structured relationships in the data. Bayesian statistics helps some models by classifying and specifying the prior distributions of any unknown parameters. Bayesian Statistics are a technique that assigns ‚Äúdegrees of belief,‚Äù\n",
    "\n",
    "P(A|B) = P(B|A) * P(A)/P(B)\n",
    "\n",
    "Bayes Naive Classifier, Bayes Optimal Classifier, Bayesian Optimization, Bayesian Belief Networks\n",
    "\n",
    "Statistical Inference\n",
    "- Bayesian inference uses Bayesian probability to summarize evidence for the likelihood of a prediction.\n",
    "\n",
    "Statistical Modeling\n",
    "- Bayesian statistics helps some models by classifying and specifying the prior distributions of any unknown parameters. \n",
    "\n",
    "***What's the prior / likelihood / posterior?*** \n",
    "\n",
    "P(A|B) is Posterior probability: Probability of hypothesis A on the observed event B.\n",
    "\n",
    "P(B|A) is Likelihood probability: Probability of the evidence given that the probability of a hypothesis is true.\n",
    "\n",
    "P(A) is Prior Probability: Probability of hypothesis before observing the evidence.\n",
    "\n",
    "P(B) is Marginal Probability: Probability of Evidence.\n",
    "\n",
    "***Why is ‚ÄúNaive‚Äù Bayes naive?***\n",
    "\n",
    "Naive Bayes is called naive because it assumes that each input variable is independent. This is a strong assumption and unrealistic for real data\n",
    "\n",
    "***What are the pros and cons of bayesian modelling?*** \n",
    "\n",
    "Pro: NB classifier is a fast and easy ML algorithm, works for binary and better for multi-class. Eager learner. Most popular choice for text classification. Con: features assumed to be independent, so can't learn relationship between features\n",
    "\n",
    "***What are the application of bayesian modelling?*** \n",
    "\n",
    "Credit scoring, medical data classification, real-time prediction, spam filtering, sentiment analysis. 1\n",
    "\n",
    "\n",
    "https://www.javatpoint.com/machine-learning-naive-bayes-classifier\n",
    "\n",
    "https://machinelearningmastery.com/bayes-theorem-for-machine-learning/\n",
    "\n",
    "https://deepai.org/machine-learning-glossary-and-terms/bayesian-statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A|B) = 0.339%\n"
     ]
    }
   ],
   "source": [
    "# calculate P(A|B) given P(A), P(B|A), P(B|not A)\n",
    "def bayes_theorem(p_a, p_b_given_a, p_b_given_not_a):\n",
    "\t# calculate P(not A)\n",
    "\tnot_a = 1 - p_a\n",
    "\t# calculate P(B)\n",
    "\tp_b = p_b_given_a * p_a + p_b_given_not_a * not_a\n",
    "\t# calculate P(A|B)\n",
    "\tp_a_given_b = (p_b_given_a * p_a) / p_b\n",
    "\treturn p_a_given_b\n",
    " \n",
    "# P(A)\n",
    "p_a = 0.0002\n",
    "# P(B|A)\n",
    "p_b_given_a = 0.85\n",
    "# P(B|not A)\n",
    "p_b_given_not_a = 0.05\n",
    "# calculate P(A|B)\n",
    "result = bayes_theorem(p_a, p_b_given_a, p_b_given_not_a)\n",
    "# summarize\n",
    "print('P(A|B) = %.3f%%' % (result * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "***How do you ensure you‚Äôre not overfitting with a model?*** (D0)\n",
    "\n",
    "Variance is low\n",
    "\n",
    "***How do you ensure you‚Äôre not underfitting with a model?*** (D0)\n",
    "\n",
    "bias is low\n",
    "\n",
    "***What‚Äôs the trade-off between bias and variance?*** (D0)\n",
    "\n",
    "Trade-off is tension between the error introduced by the bias and the variance.\n",
    "\n",
    "choose the complexity level that minimizes the overall error. \n",
    "\n",
    "If our model is too simple and has very few parameters then it may have high bias and low variance. On the other hand if our model has large number of parameters then it‚Äôs going to have high variance and low bias. So we need to find the right/good balance without overfitting and underfitting the data. \n",
    "\n",
    "\n",
    "***What‚Äôs the statistical meaning of bias and variance in the ML context. It's the variance of what?*** (D1)\n",
    "\n",
    "\n",
    "***For regression, can you decompose the mean square error into bias and variance?*** (D2)\n",
    "\n",
    "***What is Type 1 and Type 2 error?***\n",
    "- Type 1: False positive, rejection of a true null hypothesis\n",
    "- Type 2: False negative, non-rejection of a false null hypothesis\n",
    "\n",
    "***what is accuracy?***\n",
    "(TP + TN)/(TP + TN + FP + FN) = (TP + TN)/Total\n",
    "\n",
    "In a set of measurements, accuracy is closeness of the measurements to a specific value \n",
    "\n",
    "***What is precision and recall?*** (D0)\n",
    "\n",
    " - Precision TP/(TP+FP)\n",
    " - True Positive Rate (Recall, Sensitivity) TP/(TP+FN)  how well the positive class was predicted.\n",
    " - True Negative Rate (Specificity) TN/(TN+FP) how well the negative class was predicted\n",
    " \n",
    "Precision is the closeness of the measurements to each other.\n",
    " \n",
    "Recall is a metric that quantifies the number of correct positive predictions made out of all positive predictions that could have been made. Recall provides an indication of missed positive predictions.\n",
    "\n",
    "\n",
    "***How do you combine them?*** (D0)\n",
    "\n",
    "Positive likelihood ratio = TPF/FPF = Precision/Recall\n",
    "\n",
    "***What is a ROC curve?*** (D0)\n",
    "\n",
    "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
    "\n",
    " - True Positive Rate (Recall) TP/(TP+FN)\n",
    " - False Positive Rate\n",
    "\n",
    "***What is a AUC ?*** (D0)\n",
    "\n",
    "Area under the ROC curve\n",
    "\n",
    "\n",
    "***If model A achieves 97% accuracy and model B achieves 98%? Do you switch model A for B?*** (D1)\n",
    "\n",
    "\n",
    "https://www.quora.com/What-is-high-bias-and-high-variance-in-machine-learning-terminology-in-simplest-terms\n",
    "\n",
    "https://www.wikiwand.com/en/Precision_and_recall#:~:text=Recall%20is%20the%20number%20of,documents%20retrieved%20by%20that%20search.\n",
    "\n",
    "***When is accuracy not a good metric?***\n",
    "\n",
    "imbalanced set of samples\n",
    "\n",
    "For imbalanced classification, the sensitivity might be more interesting than the specificity.\n",
    "\n",
    "F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "The F-Measure is a popular metric for imbalanced classification.\n",
    "\n",
    "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/\n",
    "\n",
    "***enough training data?***\n",
    "\n",
    "how complex your problem is\n",
    "\n",
    "choice of algorithm\n",
    "\n",
    "you need roughly 10 times as many examples as there are degrees of freedom in your model. It is often a good one but if your features do not provide a good separation of targets this rule of thumb would be completely useless to your problem.\n",
    "\n",
    "But simply having more data is not useful\n",
    "\n",
    "learning curve of model performance: plot a learning curve with the number of examples you have. Maybe your choice of model is already saturated with the set size you have, or maybe you will learn that your curve is further away from stabilising than you initially thought.\n",
    "\n",
    "https://medium.com/analytics-vidhya/so-you-think-you-dont-have-enough-data-to-do-machine-learning-3b5c6c512e27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "***What is the purpose of regularization?*** (D0)\n",
    "***What regularization technics do you know?*** (D0)\n",
    "***What are the pros and cons of each?*** (D0)\n",
    "***Regularization in NN?*** (D1)\n",
    "***Regularization in decision tree?*** (D1)\n",
    "***What is the effect of L1 vs L2 regularization?*** (D2)\n",
    "***What is the bayesian interpretation of L1 and L2 regularization?*** (D3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "***What clustering algorithms do you know?*** (D0)\n",
    "***What is the k-means algorithm?*** (D1)\n",
    "***What is the GMM algorithm?*** (D2)\n",
    "***How k-means and GMM are related?*** (D2)\n",
    "***How do you evaluate the performance of a clustering algorithm?*** (D1)\n",
    "***How do you pick the right number of clusters?*** (D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels\n",
    "***What‚Äôs a kernel?*** (D1)\n",
    "***Give me an example with formulas?*** (D2)\n",
    "***Formula RBF/Gaussian kernel?*** (D2)\n",
    "***Dimension associated to RBF/Gaussian kernel?*** (D3)\n",
    "***What‚Äôs the ‚Äúkernel trick‚Äù and how is it useful?*** (D1)\n",
    "***What is an SVM?*** (D0)\n",
    "***What is support vector?*** (D1)\n",
    "***What is the margin?*** (D1)\n",
    "***In SVM, what are the slack variables? How are they useful?*** (D2)\n",
    "***When using slack variables is the margin likely to increase of decrease?*** (D2)\n",
    "***What optimization problem SVM is trying to solve (please right down the math)?*** (D3)\n",
    "***What is the pros of the dual form vs primal form?*** (D3)\n",
    "***What optimization algorithm is used to solve SVM?*** (D4)\n",
    "***Could the kernel trick be used in other algorithms than SVM?*** (D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "***What are neural networks?*** (D0)\n",
    "***What is batch normalization?*** (D2)\n",
    "***What is dropout?*** (D2)\n",
    "***What is weight decay? How different is it from L2 regularization?*** (D2)\n",
    "***Can you give me example of different activation functions for Neural Network, also explain their advantages and disadvantages?*** (D1)\n",
    "***Relu neurons can die, do you know any method to avoid that shortcoming?*** (D2)\n",
    "***What are CNNs?*** (D0)\n",
    "***What are RNNs?*** (D0)\n",
    "***Can you give me and describe me different kind of RNNs?*** (D1)\n",
    "***What are auto-encoders? What kind of auto-encoders do you know?*** (D2)\n",
    "***What is adversarial training? What is it used for?*** (D2)\n",
    "***What is a Siamese Network?*** (D2)\n",
    "***What are word embeddings?*** (D1)\n",
    "***How do you train them?*** (D2)\n",
    "***How do you handled unknown words? Rare words?*** (D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN Optimization\n",
    "\n",
    "***How do you train DNNs? (ask about cost functions and back-propagation)*** (D1)\n",
    "***How stochastic gradient descent is different from gradient descent?*** (D1)\n",
    "***What is back-propagation?*** (D1)\n",
    "***Do you know other optimizer? What are the pros and cons of each?*** (D1)\n",
    "***What is momentum?*** (D2)\n",
    "***What are second order optimization methods?*** (D3)\n",
    "***How do you set the learning rate?*** (D1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised learning\n",
    "***What is un-supervised learning? Can you give me an example?*** (D0)\n",
    "***What is semi-supervised learning?*** (D1)\n",
    "***What semi-supervised learning methods do you know?*** (D2)\n",
    "***Pros and cons of each?*** (D3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical latent models\n",
    "***What is a latent variable model? How do you optimize it?*** (D1)\n",
    "\n",
    "\n",
    "***What is a GMM (please write down the model)?*** (D1)\n",
    "\n",
    "\n",
    "***What is an HMM (please write down the model)?*** (D2)\n",
    "\n",
    "\n",
    "***Could you describe me the EM algorithm?*** (D2)\n",
    "\n",
    "\n",
    "***Can you write down the equations of the E-step and M-step?*** (D3)\n",
    "\n",
    "\n",
    "***Can you prove the convergence?*** (D4)\n",
    "\n",
    "\n",
    "***Could you describe me the EM algorithm for GMM?*** (D2)\n",
    "\n",
    "\n",
    "***Could you establish E-step and M-step equations for GMM?*** (D3)\n",
    "\n",
    "\n",
    "***Could you describe me the EM algorithm for HMM?*** (D3)\n",
    "\n",
    "\n",
    "***How do you train an HMM?*** (D3)\n",
    "\n",
    "\n",
    "***How would you handle missing data?*** (D3)\n",
    "\n",
    "\n",
    "***What are Variational Bayesian methods?*** (D4)\n",
    "\n",
    "\n",
    "***What are sampling methods (e.g Gibbs sampling)?*** (D4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence modeling\n",
    "***What is the Markov assumption?*** (D1)\n",
    "***What is an n-gram model (please write down the model) ?*** (D2)\n",
    "***How do you train them?*** (D2)\n",
    "***What if certain combinations have no examples in the data*** (D2)\n",
    "***What is an HMM (please write down the model) ?*** (D2)\n",
    "***How do you compute P(o1,o2|q1, q2) where o1 and o2 are observation and q1 and q2 are states?*** (D2)\n",
    "***How do you compute P(o1,o2) where o1 and o2 are observation?*** (D3)\n",
    "***Assuming you have o1, o2, (observation) what do you need to solve to find most likely q1, q2 (hidden states)*** (D3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble methods\n",
    "***What goal is achieved with ensemble method?*** (D0)\n",
    "\n",
    "achieve higher accuracy than individual models through bagging, boosting or stacking\n",
    "\n",
    "***What is bagging? What is the goal achieved? Can you give me an example of ML algorithm that uses bagging*** (D1)\n",
    "\n",
    "low vias, high variance, bagging reduce variance, parallel\n",
    "\n",
    "***How random forest are different from bagging?*** (D2)\n",
    "\n",
    "RF doesn't use all features and bagging use all features\n",
    "\n",
    "***What is boosting? What is the goal achieved? Can you give me an example of ML algorithm that uses boosting*** (D1)\n",
    "\n",
    "high bias, low variance, boosting reduces biasa, sequential\n",
    "\n",
    "https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees\n",
    "***Can you explain to me what is a decision tree?*** (D0)\n",
    "\n",
    "A decision tree is simply a set of cascading questions. When you get a data point (i.e. set of features and values), you use each attribute (i.e. a value of a given feature of the data point) to answer a question. The answer to each question decides the next question.\n",
    "\n",
    "\n",
    "\n",
    "***What is a decision node in decision tree?*** (D1)\n",
    "\n",
    "root node, decision node, terminal/leaf node. decision node is when a choice need to be made. There is one input and two or more output.\n",
    "\n",
    "***How do you find those nodes?*** (D2)\n",
    "\n",
    "***Tell me what is overfitting, how to prevent overfitting in decision tree?*** (D2)\n",
    "\n",
    "Pre-pruning that stop growing the tree earlier, before it perfectly classifies the training set.\n",
    "Post-pruning that allows the tree to perfectly classify the training set, and then post prune the tree. \n",
    "\n",
    "***What is a random forest?*** (D2)\n",
    "\n",
    "Random forest is a supervised learning algorithm. The \"forest\" it builds, is an ensemble of decision trees, usually trained with the ‚Äúbagging‚Äù method. The general idea of the bagging method is that a combination of learning models increases the overall result.\n",
    "\n",
    "***What is a XGBoost?***\n",
    "\n",
    "### Ensemble of Weak Learners\n",
    "\n",
    "By combining the advantages from both random forest and gradient boosting, XGBoost gave the a prediction error lower than boosting or random forest\n",
    "\n",
    "***Random Forest VS XGBoost***\n",
    "\n",
    "***Which is more likely to overfit, RF or XGB?***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction\n",
    "***What dimensionality reduction is trying to solve?*** (D0)\n",
    "***What dimensionality reduction method do you know?*** (D0)\n",
    "***Which one is a linear model?*** (D1)\n",
    "***What is PCA, how different is it from SVD?*** (D1)\n",
    "***Can you prove that PCA find the axis with the maximum variance?*** (D4)\n",
    "***Have you heard of random projection? How and why does it work?*** (D3)\n",
    "***Have you heard of non-negative matrix factorization? How do you solve this problem? What are the pros and cons vs SVD/PCA?*** (D3)\n",
    "***What is LDA? How different it is from PCA?*** (D3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Problem solving\n",
    "***What are the steps for NLP?***\n",
    "- Tokenization -> slice sentence to bag of words\n",
    "- Stemming: asked -> ask, return word to true form\n",
    "- Lemmatization -> canonical form\n",
    "\n",
    "\n",
    "***How would you implement prediction of the next word when you write text on your cell phone? Describe all the steps involved. Hints: data mining, data cleaning, model design, learning algorithm, evaluation.***\n",
    "***How would you personalize the model based on the text type by the user?***\n",
    "***Now that we have a working system. How would you implement an autocorrection/replace-as-you-type system?***\n",
    "***How would you use the user feedback to improve the autocorrection system***\n",
    "***If you are given 100k tweets and the customer information. How do you cluster them to understand the contents of the tweets?***\n",
    "***How would you design the wake word system? (Opening the mic when people say \"Alexa\")***\n",
    "***Let's say you work for a company like Amazon, and you have trained a Chinese-English machine translation system that achieves 30 BLEU.\n",
    "Now your customer says \"Thanks; now make the model ten times smaller.\" What approaches might you take? What concerns do you have? ***\n",
    "***Amazon has millions of product reviews. How would approach the problem of identifying positive and negative reviews? ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats and Math\n",
    "\n",
    "## What is sampling? \n",
    "‚ÄúData sampling is a statistical analysis technique used to select, manipulate and analyze a representative subset of data points to identify patterns and trends in the larger data set being examined.‚Äù Read the full answer here.\n",
    "\n",
    "\n",
    "## What sampling methods are there?\n",
    "\n",
    "### Probability Sampling\n",
    "\n",
    "- Simple random sampling: Software is used to randomly select subjects from the whole population.\n",
    "- Stratified sampling: Subsets of the data sets or population are created based on a common factor, and samples are randomly collected from each subgroup.\n",
    "- Cluster sampling: The larger data set is divided into subsets (clusters) based on a defined factor, then a random sampling of clusters is analyzed.\n",
    "- Multistage sampling: A more complicated form of cluster sampling, this method also involves dividing the larger population into a number of clusters. Second-stage clusters are then broken out based on a secondary factor, and those clusters are then sampled and analyzed. This staging could continue as multiple subsets are identified, clustered and analyzed.\n",
    "- Systematic sampling: A sample is created by setting an interval at which to extract data from the larger population -- for example, selecting every 10th row in a spreadsheet of 200 items to create a sample size of 20 rows to analyze.\n",
    "\n",
    "\n",
    "### Nonprobability data sampling methods :\n",
    "\n",
    "- Convenience sampling: Data is collected from an easily accessible and available group.\n",
    "- Consecutive sampling: Data is collected from every subject that meets the criteria until the predetermined sample size is met.\n",
    "- Purposive or judgmental sampling: The researcher selects the data to sample based on predefined criteria.\n",
    "- Quota sampling: The researcher ensures equal representation within the sample for all subgroups in the data set or population.\n",
    "\n",
    "https://searchbusinessanalytics.techtarget.com/definition/data-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenging Questions\n",
    "\n",
    "## What are the pros and cons of bayesian modelling?\n",
    "\n",
    "## What is the bayesian interpretation of L1 and L2 regularization?\n",
    "\n",
    "## What optimization problem SVM is trying to solve (please right down the math)?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc\n",
    "\n",
    "## Loss Function\n",
    "At its core, a loss function is incredibly simple: it‚Äôs a method of evaluating how well your algorithm models your dataset\n",
    "https://stats.stackexchange.com/questions/420416/does-knn-have-a-loss-function\n",
    "\n",
    "## Eager learning vs Lazy Learning\n",
    "\n",
    "eager learning is a learning method in which the system tries to construct a general, input-independent target function during training of the system, as opposed to lazy learning, where generalization beyond the training data is delayed until a query is made to the system. The main advantage gained in employing an eager learning method, such as an artificial neural network, is that the target function will be approximated globally during training, thus requiring much less space than using a lazy learning system. Eager learning systems also deal much better with noise in the training data. Eager learning is an example of offline learning, in which post-training queries to the system have no effect on the system itself, and thus the same query to the system will always produce the same result.\n",
    "\n",
    "The main disadvantage with eager learning is that it is generally unable to provide good local approximations in the target function.\n",
    "\n",
    "https://www.wikiwand.com/en/Eager_learning\n",
    "\n",
    "## Maximum Entropy Model\n",
    "\n",
    "https://medium.com/@phylypo/nlp-text-segmentation-using-maximum-entropy-markov-model-c6160b13b248\n",
    "\n",
    "## Active Learning\n",
    "\n",
    "## Reinforcement Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal ML\n",
    "\n",
    "## Definition\n",
    "\n",
    "Human experience multi-modal sense such as sight, hearing, smell, etc. \n",
    "\n",
    "The machine is similar but slightly different. For machines, \"modality\" refers to a particular way or mechanism of encoding information. For example, PNG and JPEG are two different way to encode image, however, the exact definition of \"Multi-modality\" is actively debated in research. The definitiion is also divided between \"Human-centric\" and \"Machine-centric\"\n",
    "\n",
    "graph and tables can be considered a good example for multi-modal\n",
    "\n",
    "A good use case of multi-modal is multimodal arithmetics: takes one image, then does text math, output another image\n",
    "\n",
    "Does well for very high dimension embeddings\n",
    "\n",
    "Multimodality (in machine learning) occurs when two or more heterogeneous inputs (recorded on different types of media) are processed by the same machine learning model, ***only if*** these inputs cannot be mapped unambiguously into one another by an algorithm\n",
    "\n",
    "https://www.youtube.com/watch?v=jReaoJWdO78\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "## What is a pipeline?\n",
    "\n",
    "chain steps together sequentially, including data preprocessing and model building\n",
    "\n",
    "## Why pipeline?\n",
    "\n",
    "1. cross validate a process not just a model. \n",
    "2. grid search or random search of not only the hyperparameters for the model but also the preprocessing steps\n",
    "\n",
    "different strategy of impuding null values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoder, column transformer, pipeline\n",
    "\n",
    "## Why is this better than pandas get dummies?\n",
    "1. no need for big dataframe, easier to manage \n",
    "2. no need to apply get dummies on new training data, problematic when out of sample data have less categories than in sample data\n",
    "3. grid search with both model and preprocessing parameters\n",
    "4. preprocess outside of sklearn can make cross validation less reliable\n",
    "\n",
    "## Ref\n",
    "https://www.youtube.com/watch?v=irHhDMbw3xo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High cardinality issue with categorical variables\n",
    "\n",
    "## Frequency Encoding\n",
    "\n",
    "heavily used in Kaggle competitions\n",
    "\n",
    "### Advantages\n",
    "1. It is very simple to implement\n",
    "2. Does not increase the feature dimensional space\n",
    "### Disadvantages\n",
    "1. If some of the labels have the same count, then they will be replaced with the same count and they will loose some valuable information.\n",
    "2. Adds somewhat arbitrary numbers, and therefore weights to the different labels, that may not be related to their predictive power\n",
    "\n",
    "## Ref:\n",
    "1. https://github.com/krishnaik06/Complete-Feature-Engineering/blob/master/2.Count_frequency_encoding.ipynb\n",
    "2. Follow this thread in Kaggle for more information: https://www.kaggle.com/general/16927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
